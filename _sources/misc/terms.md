# Important Terms & Definitions

<ul>
<li>Deep learning model: A subset of machine learning models that largely is concerned with models that perform image detection.
<li>YOLO: A deep learning model created by Ultralytics. Stands for “You Only Look Once”.
<li>CVAT: A free annotation tool we can run locally. Stands for “Computer Vision Annotation Tool”.
<li>Roboflow: A paid annotation & data augmentation tool that is hosted online.
<li>Lambda: The name of the math department server we use for our project.
<li>Bounding Boxes: The boxes that bound the object we intend to predict. These are drawn by the user in order to annotate the data.
<li>Occlusion: The blockage of an object by another object.
<li>.bashrc file: a unique file in Linux that initializes some configuration settings on start-up.
<li>Python virtual environment: a tool to help organize dependencies for different Python projects by keeping them isolated to a single environment.
<li>Training/Validation/Testing data: segments of data used in training, validating, and testing a deep learning model.
<li>Data augmentation: a technique used to increase the size of a dataset by manipulating the existing dataset.
<li>Pipe/Piping ( | ): a kind of flag in Linux that sends the output of the command before the pipe into the command after the pipe.
<li>Shell script: a type of script that runs a series of Linux commands.
<li>Nohup: a Linux command you can use to execute another Linux command and append output to a file. 
<li>And ( & ): a type of flag in Linux that is put after a command to execute it in the background.
<li>Comet: a platform for viewing current and past ML training runs, as well as compiling reports based on the data.
<li>Cross-Validation: a technique of model validation that assesses how the model will generalize to an independent dataset; i.e., how robust it is.
<li>Folds: a partition of the dataset where a segment of the dataset is saved for validation, and the rest is for training. 
<li>Underfitting: the model is unable to capture the relationship between the input and output data.
<li>Overfitting: the model performs well only on data related to its training dataset, because it picks up on patterns in the dataset rather than the object itself.
<li>Non-Maximum Suppression: a technique to select a single detection out of overlapping detections.
</ul>